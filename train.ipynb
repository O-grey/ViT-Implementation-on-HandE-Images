{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\nfrom patchify import patchify\nimport tensorflow as tf\nimport cv2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom vit import ViT","metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":"## Setting up hyper parameters.\nhp={}\nhp[\"image_size\"]=200\nhp[\"num_channels\"]=3\nhp[\"patch_size\"]=25\nhp[\"num_patches\"]=(hp['image_size']**2)//(hp['patch_size']**2)\nhp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"]*hp[\"patch_size\"]*hp[\"num_channels\"])\n\nhp[\"batch_size\"]=32\nhp[\"lr\"]=1e-4\nhp[\"num_epochs\"]=100\nhp[\"num_classes\"]=3\nhp[\"class_names\"]=[\"benign\",\"adenocarcinoma\",\"squamous_cell_carcinoma\"]\n\nhp[\"num_layers\"]=12\nhp[\"hidden_dim\"]=768\nhp[\"mlp_dim\"]=3072\nhp[\"num_heads\"]=12\nhp[\"dropout_rate\"]=0.1\n","metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\n## Creating directory for storing the files:\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n\n\ndef load_data(path, split=0.1):\n    images= shuffle(glob(os.path.join(path,\"*\",\"*.jpg\")))\n    split_size=int(len(images)*split)\n    train_x,valid_x=train_test_split(images,test_size=split_size,random_state=42)\n    return train_x,valid_x\n\n\nimport os\n\nimport os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom glob import glob\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom patchify import patchify\n\ndef process_image_label(path):\n    path = path.decode()\n    if not os.path.exists(path):\n        raise FileNotFoundError(f\"Image file not found: {path}\")\n\n    image = cv2.imread(path, cv2.IMREAD_COLOR)\n    if image is None:\n        raise ValueError(f\"Failed to load image: {path}\")\n\n    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n    image = image / 255.0\n\n    ## Preprocessing on patches:\n    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n\n    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n    patches = patches.astype(np.float32)\n\n    ## Labels\n    path = path.replace(\"\\\\\", \"/\")  # Normalize path for Windows\n    class_name = os.path.basename(os.path.dirname(path))\n    \n    if class_name not in hp[\"class_names\"]:\n        raise ValueError(f\"Class name '{class_name}' not found in class_names!\")\n\n    class_idx = hp[\"class_names\"].index(class_name)  \n    class_idx = np.array(class_idx, dtype=np.int32) \n\n    return patches, class_idx\n\ndef load_data(path, split=0.1):\n    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n    if len(images) == 0:\n        raise ValueError(f\"No images found in path: {path}\")\n\n    images = shuffle(images)\n    split_size = int(len(images) * split)\n    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n    return train_x, valid_x\n\n\n\ndef parse(path):\n    patches,labels=tf.numpy_function(process_image_label,[path],[tf.float32,tf.int32])\n    labels=tf.one_hot(labels,hp[\"num_classes\"])\n\n    patches.set_shape(hp[\"flat_patches_shape\"])\n    labels.set_shape(hp[\"num_classes\"])\n\n    return patches,labels\n\n\n\n## Creating data batches:\ndef tf_dataset(images, batch=32):\n    ds=tf.data.Dataset.from_tensor_slices((images))\n    ds=ds.map(parse).batch(batch).prefetch(8)\n    return ds\n\n\n\n\n\n## Seeding\nif __name__==\"__main__\":\n\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n\n    create_dir(\"files\")\n\n    ## Paths:\n    model_path=os.path.join(\"files\",\"model.h5\")\n    csv_path=os.path.join(\"files\",\"log.csv\")\n\n    ##Dataset:\n    train_path=\"T:\\Lung Cancer (H&E Images)\\dataset\\Train\"\n    test_path=\"T:\\Lung Cancer (H&E Images)\\dataset\\Test\"\n    train_x,valid_x=load_data(train_path)\n    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)}\")\n\n    train_ds=tf_dataset(train_x,batch=hp[\"batch_size\"])\n    valid_ds=tf_dataset(valid_x,batch=hp[\"batch_size\"])\n    \n    ## Model:\n    model = ViT(hp)\n    model.compile(\n        loss=\"categorical_crossentropy\",\n        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n        metrics=[\"acc\"]\n    )\n    \n    ## Setting Up Early-Stopping:\n    callbacks= EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\n\n    model.fit(\n        train_ds,\n        epochs=hp[\"num_epochs\"],\n        validation_data=valid_ds,\n        callbacks=callbacks\n    )","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train: 12150 - Valid: 1350\n","WARNING:tensorflow:From t:\\Lung Cancer (H&E Images)\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","Epoch 1/100\n","\u001b[1m  3/380\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:12:33\u001b[0m 183s/step - acc: 0.3854 - loss: 6.8956"]}],"execution_count":3},{"cell_type":"code","source":"pip install tensorflow-addons","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow-addons in t:\\lung cancer (h&e images)\\venv\\lib\\site-packages (0.22.0)Note: you may need to restart the kernel to use updated packages.\n","\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in t:\\lung cancer (h&e images)\\venv\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n","Requirement already satisfied: packaging in t:\\lung cancer (h&e images)\\venv\\lib\\site-packages (from tensorflow-addons) (24.2)\n"]}],"execution_count":null},{"cell_type":"code","source":"path=\"T:\\Lung Cancer (H&E Images)\\dataset\\Train\\benign\\0005.jpg\"\ncategory = path.split(os.sep)[-2]\nprint(category)\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset\n"]}],"execution_count":63},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}